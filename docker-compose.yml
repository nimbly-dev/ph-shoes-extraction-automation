version: '3.8'

services:
  airflow:
    build:
      context: ./airflow_dags
      dockerfile: Dockerfile.dev
    env_file:
      - airflow_dags/.env
    container_name: airflow
    restart: always
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__FERNET_KEY=zj0z7PXFhPKfoDI_uUxn7k8uIp6Zu7newDTC_BOKKvo=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__WORKERS=1
      - PYTHONPATH=/opt/airflow
    volumes:
      - ./airflow_dags/dags:/opt/airflow/dags
      - ./airflow_dags/logs:/opt/airflow/logs
      - ./airflow_dags/lambda_events:/opt/airflow/lambda_events
      - ./airflow_dags/utils:/opt/airflow/utils
    ports:
      - "8080:8080"
    command: ["airflow", "standalone"]


  lambda_dev:
    build:
      context: ./lambda
      dockerfile: Dockerfile.dev
    container_name: lambda_dev
    working_dir: /app
    env_file:
      - ./lambda/.env
    environment:
      - ENV_MODE=DEV
    volumes:
      - ./lambda:/app
    # Trick: run a shell instead of Lambda runtime
    entrypoint: [ "/bin/sh", "-c" ]
    command: [ "tail -f /dev/null" ]
    restart: unless-stopped

  # Optional: Glue local test environment
  # glue_dev:
  #   build:
  #     context: ./glue_jobs
  #   container_name: glue_dev
  #   working_dir: /home/glue/scripts
  #   volumes:
  #     - ./glue_jobs:/home/glue/scripts
  #   command: ["python3", "clean_asics_data.py"]
  #   restart: unless-stopped
