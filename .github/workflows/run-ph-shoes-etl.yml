name: Run ph_shoes_etl DAG

on:
  workflow_dispatch:
    inputs:
      dag_id:
        description: 'Airflow DAG ID'
        required: true
        default: 'ph_shoes_etl'

env:
  AWS_REGION: ap-southeast-1
  EC2_INSTANCE_NAME: airflow-ec2

jobs:
  trigger-dag:
    runs-on: ubuntu-latest
    environment: main

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Configure AWS credentials for SSM
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - name: Resolve EC2 instance ID
        id: get_id
        run: |
          ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=${EC2_INSTANCE_NAME}" \
                      "Name=instance-state-name,Values=running" \
            --query "Reservations[0].Instances[0].InstanceId" \
            --output text)
          echo "id=$ID" >> $GITHUB_OUTPUT

      - name: (Debug) List loaded DAGs
        run: |
          INSTANCE_ID=${{ steps.get_id.outputs.id }}
          CMD=$(aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name AWS-RunShellScript \
            --comment "Debug: list dags" \
            --parameters commands='["docker exec airflow-scheduler airflow dags list"]' \
            --region $AWS_REGION \
            --query "Command.CommandId" --output text)
          aws ssm wait command-executed \
            --command-id "$CMD" \
            --instance-id "$INSTANCE_ID" \
            --region $AWS_REGION
          aws ssm get-command-invocation \
            --command-id "$CMD" \
            --instance-id "$INSTANCE_ID" \
            --region $AWS_REGION \
            --output json

      - name: Send SSM command (unpause & trigger)
        id: send
        run: |
          INSTANCE_ID=${{ steps.get_id.outputs.id }}
          DAG_ID=${{ github.event.inputs.dag_id }}

          echo "▶ Unpause & trigger $DAG_ID on $INSTANCE_ID"
          CMD_ID=$(aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name AWS-RunShellScript \
            --comment "Trigger $DAG_ID DAG" \
            --parameters commands='[
              "docker exec airflow-scheduler airflow dags unpause '"$DAG_ID"'",
              "docker exec airflow-scheduler airflow dags trigger '"$DAG_ID"' --run-id gh-action-'"$(date +%s)"'"
            ]' \
            --region $AWS_REGION \
            --query "Command.CommandId" \
            --output text)

          echo "cmd_id=$CMD_ID" >> $GITHUB_OUTPUT

      - name: Wait for DAG run to complete
        run: |
          INSTANCE_ID=${{ steps.get_id.outputs.id }}
          DAG_ID=${{ github.event.inputs.dag_id }}
          RUN_ID="gh-action-${{ steps.send.outputs.cmd_id }}"  # same run-id you passed

          echo "⏳ Waiting for $DAG_ID run $RUN_ID to complete…"

          # max 30 loops × 1m = 30 minutes
          for i in $(seq 1 30); do
            # ask the scheduler for the run state
            CMD=$(aws ssm send-command \
              --instance-ids "$INSTANCE_ID" \
              --document-name AWS-RunShellScript \
              --parameters commands='[
                "docker exec airflow-scheduler airflow dags list-runs \
                  -d '"$DAG_ID"' \
                  --no-color \
                  --output json"
              ]' \
              --region $AWS_REGION \
              --query "Command.CommandId" \
              --output text)

            # wait for that SSM invocation
            aws ssm wait command-executed \
              --command-id "$CMD" \
              --instance-id "$INSTANCE_ID" \
              --region $AWS_REGION

            # grab the JSON output
            OUT=$(aws ssm get-command-invocation \
              --command-id "$CMD" \
              --instance-id "$INSTANCE_ID" \
              --region $AWS_REGION \
              --query "StandardOutputContent" \
              --output text)

            # pull out the state for our run_id
            STATE=$(echo "$OUT" | jq -r '.[] | select(.run_id=="'"$RUN_ID"'") | .state')

            echo "Attempt #$i: DAG run state = $STATE"

            if [[ "$STATE" == "success" ]]; then
              echo "✅ DAG run succeeded"
              break
            elif [[ "$STATE" == "failed" ]]; then
              echo "❌ DAG run failed"
              exit 1
            else
              sleep 60
            fi
          done

          # if we exit the loop without success/fail, timeout
          if [[ "$STATE" != "success" && "$STATE" != "failed" ]]; then
            echo "⏰ Timed out waiting for DAG run"
            exit 1
          fi

      - name: Fetch SSM invocation result
        if: always()
        run: |
          aws ssm get-command-invocation \
            --command-id "${{ steps.send.outputs.cmd_id }}" \
            --instance-id "${{ steps.get_id.outputs.id }}" \
            --region $AWS_REGION \
            --output json
