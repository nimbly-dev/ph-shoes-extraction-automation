# .github/workflows/run-ph-shoes-etl.yml
name: Run ph_shoes_etl DAG & trigger dbt Cloud

on:
  workflow_dispatch:
    inputs:
      dag_id:
        description: 'Airflow DAG ID'
        required: true
        default: 'ph_shoes_etl'
      run_dbt:
        description: 'Also trigger the downstream dbt Cloud job?'
        required: true
        type: choice
        default: 'true'
        options: ['true', 'false']

env:
  AWS_REGION:        ap-southeast-1
  EC2_INSTANCE_NAME: airflow-ec2

jobs:
  run-and-trigger:
    runs-on: ubuntu-latest
    environment: main               

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - name: Resolve Airflow host
        id: host
        run: |
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters Name=tag:Name,Values="${EC2_INSTANCE_NAME}" Name=instance-state-name,Values=running \
            --query "Reservations[0].Instances[0].InstanceId" --output text)
          DNS=$(aws ec2 describe-instances \
            --instance-ids "$INSTANCE_ID" \
            --query "Reservations[0].Instances[0].PublicDnsName" --output text)
          echo "airflow_host=http://${DNS}:8080" >> $GITHUB_OUTPUT

      - name: Test Airflow health
        run: |
          curl -fsS "${{ steps.host.outputs.airflow_host }}/health"

      - name: Unpause DAG via REST
        run: |
          curl -fsS -X PATCH "${{ steps.host.outputs.airflow_host }}/api/v1/dags/${{ github.event.inputs.dag_id }}" \
            -u "${{ secrets.AIRFLOW_USER }}:${{ secrets.AIRFLOW_PASSWORD }}" \
            -H "Content-Type: application/json" \
            -d '{"is_paused":false}'

      - name: Trigger DAG run via REST
        id: trigger
        run: |
          RUN_ID="gh-action-$(date +%s)"
          echo "▶ Creating DAG run $RUN_ID"
          RESPONSE=$(curl -fsS -X POST \
            "${{ steps.host.outputs.airflow_host }}/api/v1/dags/${{ github.event.inputs.dag_id }}/dagRuns" \
            -u "${{ secrets.AIRFLOW_USER }}:${{ secrets.AIRFLOW_PASSWORD }}" \
            -H "Content-Type: application/json" \
            -d '{"dag_run_id":"'"$RUN_ID"'","conf":{}}')
          echo "$RESPONSE" | jq
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT

      - name: Wait for DAG run to finish
        run: |
          for i in $(seq 1 120); do
            STATE=$(curl -fsS \
              "${{ steps.host.outputs.airflow_host }}/api/v1/dags/${{ github.event.inputs.dag_id }}/dagRuns/${{ steps.trigger.outputs.run_id }}" \
              -u "${{ secrets.AIRFLOW_USER }}:${{ secrets.AIRFLOW_PASSWORD }}" \
              | jq -r '.state')
            echo "Attempt #$i → state = $STATE"
            if [[ "$STATE" == "success" ]]; then exit 0; fi
            if [[ "$STATE" == "failed"  ]]; then exit 1; fi
            sleep 15
          done
          echo "❌ Timed-out waiting for DAG run"
          exit 1

      - name: Trigger dbt Cloud job
        if: ${{ github.event.inputs.run_dbt == 'true' }}
        env:
          ACCOUNT_ID: ${{ secrets.DBT_CLOUD_ACCOUNT_ID }}
          JOB_ID:     ${{ secrets.DBT_CLOUD_JOB_ID }}
          API_TOKEN:  ${{ secrets.DBT_API_TOKEN }}
        run: |
          echo "▶ Triggering dbt Cloud job $JOB_ID…"
          curl -fsS -X POST \
            "https://wz482.us1.dbt.com/api/v2/accounts/${ACCOUNT_ID}/jobs/${JOB_ID}/run/" \
            -H "Authorization: Token ${API_TOKEN}" \
            -H "Content-Type: application/json" \
            -d '{"cause":"Triggered after '"${{ github.event.inputs.dag_id }}"' DAG"}' \
          | jq
