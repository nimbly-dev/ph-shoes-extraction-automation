# .github/workflows/run-ph-shoes-etl.yml
name: Run ph_shoes_etl & dbt

on:
  workflow_dispatch:
    inputs:
      dag_id:
        description: 'Airflow DAG ID'
        required: true
        default: 'ph_shoes_etl'
      run_dbt:
        description: 'Trigger dbt Cloud downstream?'
        required: true
        type: choice
        options: ['true','false']
        default: 'true'

env:
  AWS_REGION:             ${{ vars.TF_VAR_AWS_REGION }}
  EC2_INSTANCE_NAME:      ${{ vars.TF_VAR_EC2_INSTANCE_NAME }}

  # Airflow credentials (set these as repo-secrets under "main" environment)
  AIRFLOW_USER:           ${{ secrets.AIRFLOW_USER }}
  AIRFLOW_PASSWORD:       ${{ secrets.AIRFLOW_PASSWORD }}

  # dbt Cloud
  DBT_ACCOUNT_ID:         ${{ secrets.DBT_CLOUD_ACCOUNT_ID }}
  DBT_JOB_ID:             ${{ secrets.DBT_CLOUD_JOB_ID }}
  DBT_API_TOKEN:          ${{ secrets.DBT_API_TOKEN }}

jobs:
  run-and-poll:
    runs-on: ubuntu-latest
    environment: main

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - name: Find Airflow EC2 instance
        id: ec2
        run: |
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters Name=tag:Name,Values="${EC2_INSTANCE_NAME}" Name=instance-state-name,Values=running \
            --query 'Reservations[0].Instances[0].InstanceId' --output text)
          if [[ -z "$INSTANCE_ID" || "$INSTANCE_ID" == "None" ]]; then
            echo "❌ No running EC2 with Name tag '${EC2_INSTANCE_NAME}'" >&2
            exit 1
          fi
          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT

      - name: Install session-manager-plugin
        run: |
          sudo apt-get update -y
          sudo apt-get install -y session-manager-plugin

      - name: Start SSM port-forward to localhost:8080
        run: |
          aws ssm start-session \
            --target "${{ steps.ec2.outputs.instance_id }}" \
            --document-name AWS-StartPortForwardingSession \
            --parameters '{"portNumber":["8080"],"localPortNumber":["8080"]}' \
            > /tmp/ssm.log 2>&1 &
          # give the plugin up to 15 s to bind
          for i in {1..15}; do
            ss -ltn | grep -q ':8080' && exit 0
            sleep 1
          done
          echo "❌ Failed to bind localhost:8080" >&2
          cat /tmp/ssm.log >&2
          exit 1

      - name: Unpause DAG
        run: |
          curl -fsS -X PATCH \
            http://localhost:8080/api/v1/dags/${{ github.event.inputs.dag_id }} \
            -u "${AIRFLOW_USER}:${AIRLOW_PASSWORD}" \
            -H "Content-Type: application/json" \
            -d '{"is_paused":false}'

      - name: Trigger DAG run
        id: trigger
        run: |
          RUN_ID="gh-$(date +%s)"
          curl -fsS -X POST \
            http://localhost:8080/api/v1/dags/${{ github.event.inputs.dag_id }}/dagRuns \
            -u "${AIRFLOW_USER}:${AIRFLOW_PASSWORD}" \
            -H "Content-Type: application/json" \
            -d '{"dag_run_id":"'"$RUN_ID"'","conf":{}}' \
          | jq .
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT

      - name: Wait for DAG to finish
        run: |
          for i in $(seq 1 120); do
            STATE=$(curl -fsS \
              http://localhost:8080/api/v1/dags/${{ github.event.inputs.dag_id }}/dagRuns/${{ steps.trigger.outputs.run_id }} \
              -u "${AIRFLOW_USER}:${AIRFLOW_PASSWORD}" \
              | jq -r .state)
            echo "Attempt #$i → $STATE"
            if [[ "$STATE" == success ]]; then exit 0; fi
            if [[ "$STATE" == failed  ]]; then exit 1; fi
            sleep 15
          done
          echo "❌ Timed out waiting for DAG" >&2
          exit 1

      - name: Trigger dbt Cloud job
        if: ${{ github.event.inputs.run_dbt == 'true' }}
        run: |
          curl -fsS -X POST \
            "https://cloud.getdbt.com/api/v2/accounts/${DBT_ACCOUNT_ID}/jobs/${DBT_JOB_ID}/run/" \
            -H "Authorization: Token ${DBT_API_TOKEN}" \
            -H "Content-Type: application/json" \
            -d '{"cause":"Triggered after DAG run"}' \
          | jq .

      - name: Wait for dbt run
        if: ${{ github.event.inputs.run_dbt == 'true' }}
        run: |
          for i in {1..60}; do
            STATUS=$(curl -fsS \
              "https://cloud.getdbt.com/api/v2/accounts/${DBT_ACCOUNT_ID}/runs/$(jq -rn "${{ steps.dbt.outputs.dbt_run_id }}")" \
              -H "Authorization: Token ${DBT_API_TOKEN}" \
              | jq -r .data.attributes.status)
            echo "dbt attempt $i → $STATUS"
            [[ "$STATUS" == Success ]] && exit 0
            [[ "$STATUS" == Error   ]] && exit 1
            sleep 10
          done
          echo "❌ dbt run timed out" >&2
          exit 1
