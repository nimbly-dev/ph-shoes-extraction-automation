name: Airflow Full CD

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'deploy or destroy the EC2 Airflow instance'
        required: true
        default: 'deploy'
        type: choice
        options:
          - deploy
          - destroy

      aws_region:
        description: 'AWS Region'
        required: true
        default: 'ap-southeast-1'

      ec2_key_name:
        description: 'EC2 KeyPair name'
        required: true
        default: 'ec2-ph-shoes-automation-keypair-name'

      ec2_instance_name:
        description: 'EC2 instance Name tag'
        required: true
        default: 'airflow-ec2'

      artifact_bucket_name:
        description: 'S3 bucket for CodeDeploy artifacts'
        required: true
        default: 'ph-shoes-airflow-artifacts'

env:
  S3_BUCKET: ${{ github.event.inputs.artifact_bucket_name }}
  S3_KEY: deployment/deployment.zip

jobs:

  build-artifacts:
    name: Build & Package
    runs-on: ubuntu-latest
    environment: main

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials for S3
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-region: ${{ github.event.inputs.aws_region }}

      - name: Debug AWS identity (S3)
        run: aws sts get-caller-identity

      - name: Build scheduler image & save to tar
        run: |
          docker build -t ph_shoes_airflow_scheduler:latest airflow_dags
          docker save ph_shoes_airflow_scheduler:latest -o ph_shoes_airflow_scheduler.tar

      - name: Archive DAGs folder
        run: tar czf dags.tar.gz -C airflow_dags .

      - name: Prepare deployment.zip
        run: |
          mkdir deploy_pkg
          cp deployment/appspec.yml         deploy_pkg/
          cp deployment/scripts/*.sh        deploy_pkg/
          cp dags.tar.gz                    deploy_pkg/
          cp ph_shoes_airflow_scheduler.tar deploy_pkg/
          cd deploy_pkg
          zip -r ../deployment.zip .

      - name: Upload deployment.zip to S3
        run: aws s3 cp deployment.zip s3://$S3_BUCKET/$S3_KEY

  provision-core:
    name: Provision Core Infra
    runs-on: ubuntu-latest
    needs: build-artifacts
    environment: main

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials for Terraform (core)
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-region: ${{ github.event.inputs.aws_region }}

      - name: Debug AWS identity (core)
        run: aws sts get-caller-identity

      - name: Setup Terraform (core)
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.6

      - name: Terraform Init & Apply (core)
        working-directory: terraform-core
        run: |
          terraform init -input=false -reconfigure
          terraform apply -auto-approve
        env:
          TF_VAR_aws_region:                    ${{ github.event.inputs.aws_region }}
          TF_VAR_app_name:                      ph-shoes-scrapper-project
          TF_VAR_environment:                   prod
          TF_VAR_s3_datalake_bucket_name:       ph-shoes-data-lake
          TF_VAR_airflow_codedeploy_bucket_name: ${{ github.event.inputs.artifact_bucket_name }}
          TF_VAR_ec2_key_name:                  ${{ github.event.inputs.ec2_key_name }}
          TF_VAR_ec2_instance_name:             ${{ github.event.inputs.ec2_instance_name }}
          TF_VAR_instance_type:                 t2.micro

  manage-ec2:
    name: Provision / Destroy EC2 Airflow
    runs-on: ubuntu-latest
    needs: provision-core
    environment: main

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials for Terraform (EC2)
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-region: ${{ github.event.inputs.aws_region }}

      - name: Debug AWS identity (EC2)
        run: aws sts get-caller-identity

      - name: Setup Terraform (EC2)
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.6

      - name: Terraform Init (EC2-Airflow)
        working-directory: terraform-ec2-airflow
        run: terraform init -input=false -reconfigure

      - name: Terraform Apply or Destroy (EC2-Airflow)
        working-directory: terraform-ec2-airflow
        run: |
          if [ "${{ github.event.inputs.action }}" = "destroy" ]; then
            terraform destroy -auto-approve
          else
            terraform apply -auto-approve
          fi

  trigger-codedeploy:
    name: Trigger CodeDeploy
    if: ${{ github.event.inputs.action == 'deploy' }}
    runs-on: ubuntu-latest
    needs: manage-ec2
    environment: main

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials for CodeDeploy
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-region: ${{ github.event.inputs.aws_region }}

      - name: Debug AWS identity (CodeDeploy)
        run: aws sts get-caller-identity

      - name: Create CodeDeploy deployment
        run: |
          aws deploy create-deployment \
            --application-name ph-shoes-airflow-codedeploy-app \
            --deployment-group-name ph-shoes-airflow-deployment-group \
            --s3-location bucket=$S3_BUCKET,bundleType=zip,key=$S3_KEY \
            --region ${{ github.event.inputs.aws_region }}
