# .github/workflows/deploy-airflow.yml
name: Airflow Full CD

on:
  workflow_dispatch:
    inputs:
      aws_region:
        description: 'AWS Region'
        required: true
        default: 'ap-southeast-1'
      ec2_key_name:
        description: 'EC2 KeyPair name'
        required: true
        default: 'ec2-ph-shoes-automation-keypair-name'
      ec2_instance_name:
        description: 'EC2 instance Name tag'
        required: true
        default: 'airflow-ec2'
      artifact_bucket_name:
        description: 'S3 bucket for CodeDeploy artifacts'
        required: true
        default: 'ph-shoes-airflow-artifacts'

env:
  S3_BUCKET: ${{ github.event.inputs.artifact_bucket_name }}
  S3_KEY:    deployment/deployment.zip

jobs:

  build-artifacts:
    name: Build & Package
    runs-on: ubuntu-latest
    environment: 
      name: main

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials for S3
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ github.event.inputs.aws_region }}

      - name: Build scheduler image & save to tar
        run: |
          docker build -t ph_shoes_airflow_scheduler:latest airflow_dags
          docker save ph_shoes_airflow_scheduler:latest -o ph_shoes_airflow_scheduler.tar

      - name: Archive DAGs folder
        run: tar czf dags.tar.gz -C airflow_dags .

      - name: Prepare deployment.zip
        run: |
          rm -rf deploy_pkg
          mkdir -p deploy_pkg/scripts
          cp deployment/appspec.yml         deploy_pkg/
          cp deployment/scripts/*.sh        deploy_pkg/scripts/
          cp dags.tar.gz                    deploy_pkg/
          cp ph_shoes_airflow_scheduler.tar deploy_pkg/
          cd deploy_pkg && zip -r ../deployment.zip .

      - name: Upload deployment.zip to S3
        run: aws s3 cp deployment.zip s3://$S3_BUCKET/$S3_KEY


  deploy-ec2-airflow:
    name: Provision / Replace EC2 (Airflow)
    needs: build-artifacts
    runs-on: ubuntu-latest
    environment:
      name: main

    env:
      TF_VAR_aws_region:        ${{ github.event.inputs.aws_region }}
      TF_VAR_ec2_key_name:      ${{ github.event.inputs.ec2_key_name }}
      TF_VAR_ec2_instance_name: ${{ github.event.inputs.ec2_instance_name }}
      TF_VAR_environment:       prod

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials for Terraform
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ github.event.inputs.aws_region }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.6

      - name: Terraform Init
        working-directory: terraform-ec2-airflow
        run: terraform init -input=false -reconfigure

      - name: Conditionally import existing EC2 KeyPair
        working-directory: terraform-ec2-airflow
        run: |
          echo "→ KeyPairs in ${TF_VAR_aws_region}:"
          aws ec2 describe-key-pairs --region ${TF_VAR_aws_region} \
            --query 'KeyPairs[*].KeyName' --output table

          if aws ec2 describe-key-pairs --region ${TF_VAR_aws_region} \
               --key-names "${TF_VAR_ec2_key_name}" >/dev/null 2>&1; then
            terraform state rm module.ec2_instance.aws_key_pair.automation_key[0] || true
            terraform import module.ec2_instance.aws_key_pair.automation_key[0] "${TF_VAR_ec2_key_name}"
          fi

      - name: Conditionally import existing SG
        working-directory: terraform-ec2-airflow
        run: |
          SG_NAME="${TF_VAR_ec2_instance_name}-sg"
          echo "→ Security-groups named $SG_NAME:"
          aws ec2 describe-security-groups --region ${TF_VAR_aws_region} \
            --filters Name=group-name,Values="$SG_NAME" \
            --query 'SecurityGroups[*].GroupId' --output table

          SG_ID=$(aws ec2 describe-security-groups --region ${TF_VAR_aws_region} \
                    --filters Name=group-name,Values="$SG_NAME" \
                    --query "SecurityGroups[0].GroupId" --output text)

          if [ -n "$SG_ID" ] && [ "$SG_ID" != "None" ]; then
            terraform state rm module.ec2_instance.aws_security_group.this[0] || true
            terraform import module.ec2_instance.aws_security_group.this[0] $SG_ID
          fi

      - name: Terraform Apply
        working-directory: terraform-ec2-airflow
        run: terraform apply -auto-approve


  trigger-codedeploy:
    name: Trigger & Wait CodeDeploy
    needs: deploy-ec2-airflow
    runs-on: ubuntu-latest
    environment:
      name: main

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS credentials for CodeDeploy
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ github.event.inputs.aws_region }}

      - name: Create & wait for CodeDeploy deployment (with overwrite + debug)
        env:
          AWS_REGION: ${{ github.event.inputs.aws_region }}
        run: |
          set -euxo pipefail

          # 1) Kick off deployment, overwrite any existing files
          DEPLOY_ID=$(aws deploy create-deployment \
            --application-name      ph-shoes-airflow-codedeploy-app \
            --deployment-group-name ph-shoes-airflow-deployment-group \
            --s3-location bucket=$S3_BUCKET,bundleType=zip,key=$S3_KEY \
            --file-exists-behavior OVERWRITE \
            --region $AWS_REGION \
            --query deploymentId --output text)
          echo "Deployment started: $DEPLOY_ID"

          # 2) Wait—on failure, dump detailed info
          if ! aws deploy wait deployment-successful \
              --deployment-id "$DEPLOY_ID" \
              --region $AWS_REGION; then

            echo "❌ CodeDeploy FAILED—dumping debug information…"

            echo "--- Deployment Info ---"
            aws deploy get-deployment \
              --deployment-id "$DEPLOY_ID" \
              --region $AWS_REGION \
              --output json

            echo "--- Instances in this deployment ---"
            INSTANCES=$(aws deploy list-deployment-instances \
                          --deployment-id "$DEPLOY_ID" \
                          --region $AWS_REGION \
                          --query "instancesList[]" --output text)
            echo "$INSTANCES"

            for I in $INSTANCES; do
              echo "--- Instance $I summary ---"
              aws deploy get-deployment-instance \
                --deployment-id "$DEPLOY_ID" \
                --instance-id "$I" \
                --region $AWS_REGION \
                --output json
            done

            exit 1
          fi

          echo "✅ CodeDeploy deployment $DEPLOY_ID succeeded."